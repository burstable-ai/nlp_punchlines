{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2cad74-b61f-4470-98d3-feb1500b3db4",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "# Can you teach an AI to tell jokes?\n",
    "\n",
    "In this tutorial we will explore what happens when we get an AI to tell jokes using Transformer models and PyTorch, how much we can improve the performance with fine-tuning, and some of the major limitations we encounter along the way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95ca7d-b081-4ed8-bc87-bbdd45812d22",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "This tutorial will walk through the following:\n",
    "\n",
    "* [1.JokesDataset](1.JokesDataset.ipynb): Create a dataset of jokes to use for experimentation and model training\n",
    "* [2.FakePunchlines](2.FakePunchlines.ipynb): Use a pretrained Transformer models to generate punchlines\n",
    "* [3.PunchlineClassifier](3.PunchlineClassifier.ipynb): Train a \"joke classifier\" to tell the difference between \"real\" human-generated punchlines and \"fake\" Transformer-generated punchlines\n",
    "* [4.FineTune](4.FineTune.ipynb): Use our jokes dataset to fine-tune the Transformer models and improve the punchlines they generate\n",
    "* [5.Performance](5.Performance.ipynb): Use our joke classifier to quantify the improved performance we got from fine-tuning\n",
    "* [6.NLPChallenges](6.NLPChallenges.ipynb): Examine some of the problems in current NLP models, as highlighted by this joke-telling exercise\n",
    "    \n",
    "Each step has its own Jupyter Notebook, so you can walk through the details of each processing step if you desire.  This notebook walks through a high-level view of the problem, with each step implemented as a single command.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc593eb0-9642-42ee-94f0-6b1ac4bb3850",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "NOTE: Some commands make take several hours to run&mdash;these commands are better run from the command line using `screen` or `tmux`, so that they can be run as a detached background process that does not require a persistent internet connection.  You can get a terminal window by selecting **File&rarr;New&rarr;Terminal**.  You can find documentation for `screen` [here](https://linuxize.com/post/how-to-use-linux-screen/) and for `tmux` [here](https://linuxize.com/post/getting-started-with-tmux/).  Both are already installed on Cloudburst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40964901-780f-40e7-807a-fab829c5d06b",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 1. The Jokes Dataset\n",
    "    \n",
    "For this project, we'll use a large, publicly available dataset of jokes: the \"One Million Reddit Jokes\" dataset, which covers jokes from the /r/jokes subreddit from April 1, 2020 and earlier. The jokes dataset is provided here in `./data/one-million-reddit-jokes.csv`. You can also download the jokes dataset directly from Kaggle [here](https://www.kaggle.com/pavellexyr/one-million-reddit-jokes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f30b9c-894b-4162-8f50-e51430665413",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Jokes can take many forms; some are just narrative stories with amusing or suprising endings. Some are \"My life\" (as in, \"my life is a joke\", which appears 9 separate times in this dataset).\n",
    "    \n",
    "For this project, we'll restrict ourselves to a narrow, semi-formulaic set of jokes that include a \"setup\" question, followed by a \"punchline\" answer, and we'll require the punchlines to be rather short: 20 words or less.  \n",
    "    \n",
    "We also want to clean up the data to make sure we have a set of \"real\" jokes, removing jokes that have subsequently been deleted or removed and whose punchlines are therefore missing, and those that did not get a single upvote.  Finally, we want to remove duplicate jokes, while summing the upvotes across every instance of a unique joke.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d5a18-04b6-4a1e-8f71-05a00eff67fe",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "This leaves us with a final dataset of ~150,000 short \"Q/A\" format jokes.\n",
    "    \n",
    "We will split this dataset into \"train\" and \"test\" sets, and also copy a small subset of the \"test\" jokes into a \"minitest\" dataset that we can use for development purposes.\n",
    "    \n",
    "If your interested in the details of *why* we made these choices, or how we do the data cleaning, see [1_JokesDataset.ipynb](1_JokesDataset.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b07478-66fe-47b1-ab26-87ef1166a3c6",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "You can run this functionality here in the Notebook by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4cf0c2-722d-433a-b45c-28b027d452cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in raw jokes data...\n",
      "   1000000 jokes in the raw dataset\n",
      "    146796 jokes in the final dataset (Q|A format, short punchlines, 1+ upvotes)\n",
      "Joke splits written to:\n",
      "    146796 in data/short_jokes_all.csv\n",
      "    102757 in data/short_jokes_train.csv\n",
      "     44039 in data/short_jokes_test.csv\n",
      "       300 in data/short_jokes_minitest.csv\n"
     ]
    }
   ],
   "source": [
    "from clean_data import clean_data\n",
    "clean_data(file='data/one-million-reddit-jokes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c512e-62c3-434f-b95d-a83aa7a59bb0",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Alternatively, you can run the cleaning script in the terminal from the command line with:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be605fea-0d70-4e0d-8ccb-412ae1d92765",
   "metadata": {},
   "source": [
    "    prompt$> python clean_data.py data/one-million-reddit-jokes.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06952ab7-401f-4ccc-a9e4-9214d4089b6a",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 2. \"Fake\" Punchlines, generated by an AI\n",
    "\n",
    "Before we try to train an AI to tell jokes, we should check what can be done out-of-the-box with existing, pre-trained Transformer models.\n",
    "    \n",
    "We'll use GPT-2, which is the freely-available forerunner of the recent GPT-3 text-generation model that generated tons of press last year. GPT-2 and GPT-3 are built to take a text prompt, and then generate additional new text that \"continues\" the thread.\n",
    "\n",
    "Given a joke setup, can GPT-2 produce a plausible punchline? And is it funny?\n",
    "    \n",
    "A more detailed walk-through of this step can be found in [2_FakePunchlines.ipynb](2_FakePunchlines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ea357-51b1-4b2b-baab-2c663730f950",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Because GPT-2 is trained to be general-purpose text generator, and not necessarily to answer questions or provide punchlines, we give it a few in-text clues to help it recognize the Q/A joke format we are trying to produce, so that each joke is formatted as:\n",
    "    \n",
    "> \"Question: [joke setup, ends in '?'] Answer: [joke punchline]\"\n",
    "    \n",
    "We then load the GPT-2 model and its associated tokenizer, which will convert text strings into numeric input for the model.  We pass it a \"prompt\", in the form \n",
    "    \n",
    "> \"Question: [joke setup] Answer:\" \n",
    "    \n",
    "and ask it to generate the continuing text that should come after \"Answer:\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad8462-a452-4105-b296-5d3944c28780",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The code checks to see if a GPU is available, and to use it if it is.  The GPU gets a 6.5x speedup over the CPU in our tests, but that still means it will take hours to generate fake punchlines for our full dataset of 140,000+ jokes.\n",
    "\n",
    "Let's do a small run with our \"minitest\" dataset and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c294be73-fa4f-464e-92ef-a55bbe660225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 jokes in the dataset\n",
      "Using checkpoint \"gpt2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on jokes 0:100 out of 300 -- 0:00:00.000005\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 0:100 to CSV\n",
      "Working on jokes 100:200 out of 300 -- 0:00:32.385260\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 100:200 to CSV\n",
      "Working on jokes 200:300 out of 300 -- 0:01:00.942600\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 200:300 to CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This runs locally in the Notebook on our small 300-joke \"mini-test\" set.  \n",
    "\n",
    "from fake_punchlines import add_fake_punchlines\n",
    "\n",
    "add_fake_punchlines('data/short_jokes_minitest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6de3dd7-c867-4f90-9028-ec6ab0e66e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Did you know Google now has a platform for recording your bowel movements?\n",
      "  Answer: It's called Google Sheets.\n",
      "    Fake: Yes, there are multiple platforms that you can connect to to record bowel movements such as xray, ultrasound, etc. There are a few things you\n",
      "----\n",
      "Question: What do you call a boat full of dentists?\n",
      "  Answer: A tooth ferry\n",
      "    Fake: A boat full of dentists. In this case, this is an absolutely fantastic combination of both, one with a proper proper dental service and one with\n",
      "----\n",
      "Question: How do you know someone is feeling horny?\n",
      "  Answer: They click on this post\n",
      "    Fake: I know someone who feels horny. I don't want to go through that experience again, and that is a good thing. Most people who get horny\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Take a look at exampes of the real jokes and the fake punchlines we just created\n",
    "\n",
    "import pandas as pd\n",
    "mini_jokes = pd.read_csv('data/short_jokes_minitest.csv')\n",
    "mini_fakes = pd.read_csv('data/short_jokes_minitest_fake.csv')\n",
    "for i in range(3):\n",
    "    print('Question: {}'.format(mini_jokes.iloc[i]['setup']))\n",
    "    print('  Answer: {}'.format(mini_jokes.iloc[i]['punchline']))\n",
    "    print('    Fake: {}'.format(mini_fakes.iloc[i]['punchline']))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12129770-47d1-4192-996a-d4e33378536e",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "    \n",
    "It takes about 30 seconds to generate punchlines for a batch of 100 jokes (your mileage may vary).  This means generating fake punchlines for the full dataset will take almost 12 hours!\n",
    "    \n",
    "If you have a stable internet connection and can leave your laptop open, you can run them right here in the notebook and hope that you don't get disconnected.\n",
    "\n",
    "However, a better choice is to run them from the terminal, using screen or tmux to background the process. That way, you launch the run, close your laptop, and walk away. The process will run overnight and the output will be waiting for you when you get up in the morning.\n",
    "\n",
    "To run in the background:\n",
    "* Open a terminal\n",
    "* Enter `screen`\n",
    "* Run the following command:\n",
    "```\n",
    "    python fake_punchlines.py data/short_jokes_train.csv\n",
    "```\n",
    "* Detach from the `screen`.\n",
    "    \n",
    "Then do the same for `data/short_jokes_test.csv`.\n",
    "    \n",
    "More detailed instructions on how to do this can be found in the [FakePunchlines Notebook](2_FakePunchlines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb9f90-22b1-491e-9ea7-c9911a9d0397",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 3. A Classifier to recognize \"real\" and \"fake\" punchlines\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791599fe-3e2f-43c3-ac56-51dc1a51a20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

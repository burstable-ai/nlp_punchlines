{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2cad74-b61f-4470-98d3-feb1500b3db4",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "# Can you teach an AI to tell jokes?\n",
    "\n",
    "In this tutorial we will explore what happens when we get an AI to tell jokes using Transformer models and PyTorch, how much we can improve the performance with fine-tuning, and some of the major limitations we encounter along the way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95ca7d-b081-4ed8-bc87-bbdd45812d22",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "This tutorial will walk through the following:\n",
    "\n",
    "* [1.JokesDataset](1.JokesDataset.ipynb): Create a dataset of jokes to use for experimentation and model training\n",
    "* [2.FakePunchlines](2.FakePunchlines.ipynb): Use a pretrained Transformer models to generate punchlines\n",
    "* [3.PunchlineClassifier](3.PunchlineClassifier.ipynb): Train a \"joke classifier\" to tell the difference between \"real\" human-generated punchlines and \"fake\" Transformer-generated punchlines\n",
    "* [4.FineTune](4.FineTune.ipynb): Use our jokes dataset to fine-tune the Transformer models and improve the punchlines they generate\n",
    "* [5.Performance](5.Performance.ipynb): Use our joke classifier to quantify the improved performance we got from fine-tuning\n",
    "* [6.NLPChallenges](6.NLPChallenges.ipynb): Examine some of the problems in current NLP models, as highlighted by this joke-telling exercise\n",
    "    \n",
    "Each step has its own Jupyter Notebook, so you can walk through the details of each processing step if you desire.  This notebook walks through a high-level view of the problem, with each step implemented as a single command.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc593eb0-9642-42ee-94f0-6b1ac4bb3850",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "NOTE: Some commands make take several hours to run&mdash;these commands are better run from the command line using `screen` or `tmux`, so that they can be run as a detached background process that does not require a persistent internet connection.  You can get a terminal window by selecting **File&rarr;New&rarr;Terminal**.  You can find documentation for `screen` [here](https://linuxize.com/post/how-to-use-linux-screen/) and for `tmux` [here](https://linuxize.com/post/getting-started-with-tmux/).  Both are already installed on Cloudburst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40964901-780f-40e7-807a-fab829c5d06b",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 1. The Jokes Dataset\n",
    "    \n",
    "For this project, we'll use a large, publicly available dataset of jokes: the \"One Million Reddit Jokes\" dataset, which covers jokes from the /r/jokes subreddit from April 1, 2020 and earlier. The jokes dataset is provided here in `./data/one-million-reddit-jokes.csv`. You can also download the jokes dataset directly from Kaggle [here](https://www.kaggle.com/pavellexyr/one-million-reddit-jokes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f30b9c-894b-4162-8f50-e51430665413",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Jokes can take many forms; some are just narrative stories with amusing or suprising endings. Some are \"My life\" (as in, \"my life is a joke\", which appears 9 separate times in this dataset).\n",
    "    \n",
    "For this project, we'll restrict ourselves to a narrow, semi-formulaic set of jokes that include a \"setup\" question, followed by a \"punchline\" answer, and we'll require the punchlines to be rather short: 20 words or less.  \n",
    "    \n",
    "We also want to clean up the data to make sure we have a set of \"real\" jokes, removing jokes that have subsequently been deleted or removed and whose punchlines are therefore missing, and those that did not get a single upvote.  Finally, we want to remove duplicate jokes, while summing the upvotes across every instance of a unique joke.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d5a18-04b6-4a1e-8f71-05a00eff67fe",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "This leaves us with a final dataset of ~150,000 short \"Q/A\" format jokes.\n",
    "    \n",
    "We will split this dataset into \"train\" and \"test\" sets, and also copy a small subset of the \"test\" jokes into a \"minitest\" dataset that we can use for development purposes.\n",
    "    \n",
    "If your interested in the details of *why* we made these choices, or how we do the data cleaning, see [1_JokesDataset.ipynb](1_JokesDataset.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b07478-66fe-47b1-ab26-87ef1166a3c6",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "You can run this functionality here in the Notebook by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4cf0c2-722d-433a-b45c-28b027d452cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in raw jokes data...\n",
      "   1000000 jokes in the raw dataset\n",
      "    146796 jokes in the final dataset (Q|A format, short punchlines, 1+ upvotes)\n",
      "Joke splits written to:\n",
      "    146796 in data/short_jokes_all.csv\n",
      "    102757 in data/short_jokes_train.csv\n",
      "     44039 in data/short_jokes_test.csv\n",
      "       300 in data/short_jokes_minitest.csv\n"
     ]
    }
   ],
   "source": [
    "from clean_data import clean_data\n",
    "clean_data(file='data/one-million-reddit-jokes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c512e-62c3-434f-b95d-a83aa7a59bb0",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Alternatively, you can run the cleaning script in the terminal from the command line with:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be605fea-0d70-4e0d-8ccb-412ae1d92765",
   "metadata": {},
   "source": [
    "    prompt$> python clean_data.py data/one-million-reddit-jokes.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06952ab7-401f-4ccc-a9e4-9214d4089b6a",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 2. \"Fake\" Punchlines, generated by an AI\n",
    "\n",
    "Before we try to train an AI to tell jokes, we should check what can be done out-of-the-box with existing, pre-trained Transformer models.  We'll use GPT-2, which is the freely-available forerunner of the recent GPT-3 text-generation model that generated tons of press last year. \n",
    "    \n",
    "GPT-2 and GPT-3 are both *auto-regressive* models, which use only the \"decoder\" part of the Transformer neuron architecture and are optimized for generating text.  They are built to take a text prompt and generate additional new text that \"continues\" the thread.\n",
    "\n",
    "Given a joke setup, can GPT-2 produce a plausible punchline? And is it funny?\n",
    "    \n",
    "A more detailed walk-through of this step can be found in [2_FakePunchlines.ipynb](2_FakePunchlines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ea357-51b1-4b2b-baab-2c663730f950",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Because GPT-2 is trained to be general-purpose text generator, and not necessarily to answer questions or provide punchlines, we give it a few in-text clues to help it recognize the Q/A joke format we are trying to produce, so that each joke is formatted as:\n",
    "    \n",
    "> \"Question: [joke setup, ends in '?'] Answer: [joke punchline]\"\n",
    "    \n",
    "We then load the GPT-2 model and its associated tokenizer, which will convert text strings into numeric input for the model.  We pass it a \"prompt\", in the form \n",
    "    \n",
    "> \"Question: [joke setup] Answer:\" \n",
    "    \n",
    "and ask it to generate the continuing text that should come after \"Answer:\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad8462-a452-4105-b296-5d3944c28780",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The code checks to see if a GPU is available, and to use it if it is.  The GPU gets a 6.5x speedup over the CPU in our tests, but that still means it will take hours to generate fake punchlines for our full dataset of 140,000+ jokes.\n",
    "\n",
    "Let's do a small run with our \"minitest\" dataset and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c294be73-fa4f-464e-92ef-a55bbe660225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 jokes in the dataset\n",
      "Using checkpoint \"gpt2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on jokes 0:100 out of 300 -- 0:00:00.000005\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 0:100 to CSV\n",
      "Working on jokes 100:200 out of 300 -- 0:00:32.385260\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 100:200 to CSV\n",
      "Working on jokes 200:300 out of 300 -- 0:01:00.942600\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing 200:300 to CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This runs locally in the Notebook on our small 300-joke \"mini-test\" set.  \n",
    "\n",
    "from fake_punchlines import add_fake_punchlines\n",
    "\n",
    "add_fake_punchlines('data/short_jokes_minitest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6de3dd7-c867-4f90-9028-ec6ab0e66e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Did you know Google now has a platform for recording your bowel movements?\n",
      "  Answer: It's called Google Sheets.\n",
      "    Fake: Yes, there are multiple platforms that you can connect to to record bowel movements such as xray, ultrasound, etc. There are a few things you\n",
      "----\n",
      "Question: What do you call a boat full of dentists?\n",
      "  Answer: A tooth ferry\n",
      "    Fake: A boat full of dentists. In this case, this is an absolutely fantastic combination of both, one with a proper proper dental service and one with\n",
      "----\n",
      "Question: How do you know someone is feeling horny?\n",
      "  Answer: They click on this post\n",
      "    Fake: I know someone who feels horny. I don't want to go through that experience again, and that is a good thing. Most people who get horny\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Take a look at exampes of the real jokes and the fake punchlines we just created\n",
    "\n",
    "import pandas as pd\n",
    "mini_jokes = pd.read_csv('data/short_jokes_minitest.csv')\n",
    "mini_fakes = pd.read_csv('data/short_jokes_minitest_fake.csv')\n",
    "for i in range(3):\n",
    "    print('Question: {}'.format(mini_jokes.iloc[i]['setup']))\n",
    "    print('  Answer: {}'.format(mini_jokes.iloc[i]['punchline']))\n",
    "    print('    Fake: {}'.format(mini_fakes.iloc[i]['punchline']))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5eb029-3afa-4030-b987-9d08bedbab9d",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "    \n",
    "There are a few interesting things to note here.\n",
    "\n",
    "* Responses are generally on-topic and sound (mostly) like coherent English.  This is what GPT-2 is good at!\n",
    "* The responses just ramble on and cut off arbitrarily.  We set a 30-token limit if no end-of-string (EOS) token is received; an EOS token is basically *never* generated.  GPT-2 is not good at knowing when to shut up!\n",
    "* GPT-2 often answers questions with more questions (although structuring our prompts with explicit \"Question:/Answer:\" format seems to have helped a lot compared to my previous tests...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12129770-47d1-4192-996a-d4e33378536e",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "    \n",
    "It takes about 30 seconds to generate punchlines for a batch of 100 jokes (your mileage may vary somewhat).  \n",
    "    \n",
    "In the next step, we'll train a joke classifier to distinguish between real and fake jokes, but to do that, we'll need to generate a big dataset of fake punchlines.  Based on our small batch example, generating fake punchlines for the full dataset will take almost 12 hours!\n",
    "    \n",
    "If you have a stable internet connection and can leave your laptop open, you can run them right here in the notebook and hope that you don't get disconnected.\n",
    "\n",
    "However, a better choice is to run them from the terminal, using screen or tmux to background the process. That way, you launch the run, close your laptop, and walk away. The process will run overnight and the output will be waiting for you when you get up in the morning.\n",
    "\n",
    "To run in the background:\n",
    "* Open a terminal\n",
    "* Enter `screen`\n",
    "* Run the following command:\n",
    "```\n",
    "    python fake_punchlines.py data/short_jokes_train.csv\n",
    "```\n",
    "* Detach from the `screen`.\n",
    "    \n",
    "Then do the same for `data/short_jokes_test.csv`.\n",
    "    \n",
    "More detailed instructions on how to do this can be found in the [FakePunchlines Notebook](2_FakePunchlines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb9f90-22b1-491e-9ea7-c9911a9d0397",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 3. A Classifier to recognize \"real\" and \"fake\" punchlines\n",
    "    \n",
    "We've seen that GPT-2 straight out of the box has some trouble telling jokes.  For one thing, she tends to ramble on and on, much longer than typical Q/A joke punchlines.  She also often answers questions with questions, much more so than actual punchlines do.  If the jokes make sense at all, they usually aren't very funny.  \n",
    "    \n",
    "In short, GPT-2 can't fool a human into thinking that she's a real, human comedian.\n",
    "    \n",
    "But can GPT-2 fool another AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf122a2-713c-4242-b629-7da69b50a314",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Let's find out, by training a classifier to distinguish \"real\" from \"fake\" jokes.  \n",
    "    \n",
    "For this exercies, we'll use a different type of Transformer model: an *auto-encoding* model.  Models of this type use only the \"encoder\" part of the Transformer neuron architecture, and are optimized for making sense of a text-string (including classifying it).  The particular auto-encoder we use here is called BERT.  \n",
    "    \n",
    "Can GPT-2 fool BERT into thinking her jokes are real?  Or will BERT be able to tell the difference between her jokes and those from a human(?) comedian on Reddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7bb81-223d-4360-b818-33e810e3298d",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The process of training and testing BERT to distinguish between real and fake jokes is implemented here in the *classify_punchines()* function in [punchline_classifier.py](punchline_classifier.py).  \n",
    "    \n",
    "We need to give him a training set of jokes, including both real jokes and fake jokes, for him to use to train the classifier.  We also give him a test set of jokes, including both real and fake, so that he can quantify how well he is able to do.\n",
    "    \n",
    "It takes several hours to train BERT on the full dataset, so we've made it easy to \"downsample\" the dataset by a large factor (e.g., 20x).  Even using this small subset of the training data, BERT is able to achieve good quality differentiation between the real and fake jokes.  Training on the full dataset only improves the results by a small amount.  \n",
    "    \n",
    "If you want to train on the full dataset, we recommend doing it from the command line using *screen*, as explained in [3.PunchlineClassifier](3.PunchlineClassifier.ipynb).  \n",
    "    \n",
    "For now, let's just train on 1/20th of the data, right here in the notebook (should take < 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791599fe-3e2f-43c3-ac56-51dc1a51a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-22e578e895d47822\n",
      "Reusing dataset csv (/home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b99e239cdef4c20b55b4b25b950d456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-174f232c5e5ea289.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-3d38ffa341bd5fb6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10276 rows in the train dataset (20x downsampled).\n",
      "4404 rows in the test dataset (20x downsampled).\n",
      "Using checkpoint \"bert-base-uncased\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-04f3f1f28d3cfd09.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-66a2ee66f6cc9294.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-f7ebf296e01a0926.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-1d0d449927fe612f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no EOS token detected.  Adding an EOS token\n",
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1284/3855 [02:12<04:25,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.009, Accuracy: 0.971, F1: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2569/3855 [04:42<02:15,  9.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.007, Accuracy: 0.982, F1: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3854/3855 [07:12<00:00,  9.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.001, Accuracy: 0.983, F1: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3855/3855 [07:34<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as models/ClassifyJokes_bert_0.05subset_2021-12-21.pt\n"
     ]
    }
   ],
   "source": [
    "from punchline_classifier import classify_punchlines\n",
    "\n",
    "train_files = ['data/short_jokes_train.csv','data/short_jokes_train_fake.csv']\n",
    "test_files = ['data/short_jokes_test.csv','data/short_jokes_test_fake.csv']\n",
    "\n",
    "# Set downsample=1 or leave out to train on the full training set (it defaults to 1)\n",
    "model = classify_punchlines(train_files, test_files, downsample=20)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efce87-61fe-41f0-b6e3-dcb6a7c6b4ad",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Notice that BERT is able to achieve 97%+ accuracy, even just training on a small subset of the available training data.\n",
    "    \n",
    "So the answer is \"No\", out-of-the-box GPT-2 cannot fool BERT with her joke-telling abilities.\n",
    "    \n",
    "But what if we train her *specifically to tell jokes*?  Can she get better at it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835298b-b28b-4468-afd2-fdf792d4376a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

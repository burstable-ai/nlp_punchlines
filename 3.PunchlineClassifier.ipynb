{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2860c465-b905-4230-a182-e45f49a5621b",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 3. Recognizing \"Real\" vs. \"Fake\" jokes\n",
    "\n",
    "In [2.FakePunchlines](2.FakePunchlines.ipynb), we got GPT-2 to generate the punchlines to some jokes.  A human can pretty easily tell which are the real punchlines and which are the GPT-2-generated ones.  But can GPT-2 fool another AI?\n",
    "    \n",
    "In this Notebook, we'll use the HugginFace [transformers](https://github.com/huggingface/transformers) library to train an NLP classifier to distinguish between the real joke punchlines and the fake ones generated by GPT-2.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3474abf-3593-47bf-bef6-7dddae41db88",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "We start by loading in our training and test datasets that were generated in [1.JokesDataset](1.JokesDataset.ipynb).  While we're trying to get things to work, let's downsample the data by 100x (i.e., use only 1% of the data), just so that things will run fast.  When we're ready to train for real, we'll use a factor of 1x (no downsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be1b1dc-117a-4213-bf32-636f913d51b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-22e578e895d47822\n",
      "Reusing dataset csv (/home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d0ac9c000248c0b92dc8fdc1108808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-ebffb6372e26d996.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-e67abdb78f2c3222.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056 rows in the train dataset (100x downsampled).\n",
      "881 rows in the test dataset (100x downsampled).\n"
     ]
    }
   ],
   "source": [
    "# Load our dataset of real and fake jokes, split into training and test sets\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# For development purposes, we downsample by 100x, just so things run fast\n",
    "downsample_factor = 100\n",
    "# Load the data, filter out any non-string input (it breaks the code), and downsample\n",
    "dataset = load_dataset('csv', data_files={'train':['data/short_jokes_train.csv','data/short_jokes_train_fake.csv'],\n",
    "                                          'test':['data/short_jokes_test.csv','data/short_jokes_test_fake.csv']})\n",
    "dataset = dataset.filter(lambda ex,j: ((type(ex['setup'])==str) & (type(ex['punchline'])==str) & \n",
    "                                       (j%downsample_factor==0)),                         \n",
    "                         with_indices=True)\n",
    "print('{} rows in the train dataset ({}x downsampled).'.format(dataset['train'].num_rows,downsample_factor))\n",
    "print('{} rows in the test dataset ({}x downsampled).'.format(dataset['test'].num_rows,downsample_factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71388c8f-d022-4aca-a001-3f8061ff4c9e",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "We've loaded the data as a HuggingFace \"dataset\", which can be read incrementally from disk (instead of loading the whole dataset into memory at once), and which can be fed nicely into PyTorch DataLoaders when it comes time to train a model.  \n",
    "\n",
    "Notice that we've mixed together the \"real\" jokes and the \"fake\" jokes (whose punchlines are generated by GPT-2) in both our \"train\" and \"test\" datasets.  The difference is that all the \"real\" jokes have score > 0 (because we only selected jokes with at least one upvote), whereas we created all the fake jokes with score = 0.\n",
    "   \n",
    "Let's take a quick look at how the data are formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f16cee6-06f8-40a6-be97-7cb819f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['setup', 'punchline', 'score'],\n",
      "        num_rows: 2056\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['setup', 'punchline', 'score'],\n",
      "        num_rows: 881\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d66d7-7de1-4988-a722-ea9c893ea0f0",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The dataset is stored as a DatasetDict, which has two components, \"train\" and \"test\", each of which contain the data rows and the \"features\" from the CSV.\n",
    "    \n",
    "We can look at the first examples of the \"real\" and the \"fake\" jokes in our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9521a00c-444c-48b4-906b-4f1a30f79f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A joke with a human-generated punchline:\n",
      "{'setup': 'Did you know Google now has a platform for recording your bowel movements?', 'punchline': \"It's called Google Sheets.\", 'score': 9}\n",
      "\n",
      "A joke with a GPT2-generated punchline:\n",
      "{'setup': 'What do you get when you cross a sheep and a kangaroo?', 'punchline': 'You get the breed to sign something for you! (Kangaroos are typically male, and we only cross males once in a while). So', 'score': 0}\n"
     ]
    }
   ],
   "source": [
    "print('A joke with a human-generated punchline:')\n",
    "print(dataset['test'][0])\n",
    "print()\n",
    "print('A joke with a GPT2-generated punchline:')\n",
    "print([x for x in dataset['test'] if x['score']==0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be53482b-ea00-4f19-8e5e-069884e6eb9f",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Now that we've loaded our data, let's use it to train a model!\n",
    "    \n",
    "We're not, however, going to start training from scratch.  \n",
    "    \n",
    "Transformer models, each with 100s of millions or even 100s of *billions* of free parameters trained on an enormous corpus of documents, are very expensive to train, in terms of both time and compute costs.  Not only do we not want to wait through and pay for all that compute time, but the carbon footprint of training a state-of-the-art model is [LARGE](https://huggingface.co/course/chapter1/4?fw=pt#transformers-are-big-models).  \n",
    "    \n",
    "Instead, we will use [transfer learning](https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2).  To do that, we start from a pre-trained model, which has already been trained through many epochs on huge document datasets.  We will then do some \"fine-tuning\" training using our Jokes dataset to produce a classifier that is particularly good at distinguishing human-generated vs. GPT2-generated jokes.\n",
    "    \n",
    "Let's start with the [BERT model](https://arxiv.org/pdf/1810.04805.pdf) from Google's AI Language lab.  We're going to use it to do \"sequence classification\", where the model decides if one sequence (in our case, the punchline) is an appropriate follow-on from a previous sequence (in our case, the setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc012c9-ec2d-428c-82fc-bf6f2f561422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using checkpoint \"bert-base-uncased\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no EOS token detected.  Adding an EOS token\n"
     ]
    }
   ],
   "source": [
    "import model_tools as mtools\n",
    "\n",
    "checkpoint, tokenizer, model = mtools.load_model('bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bcc09-6bc6-49ab-a05f-c34c15f785bd",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "We got some warnings that we've loaded a version of BERT that is not already set up for sequence classification, and that it needs some training to be ready to use this way.  That's okay!  Training is exactly what we are about to do.\n",
    "    \n",
    "But first, we need to tokenize the data using BERT's tokenizer, so that our text is encoded using the same token mapping that BERT has been pre-trained to expect.  \n",
    "    \n",
    "Two additional processes will happen as part of this tokenization: we'll pad the tokenized strings in each batch to be the same length, so that they can be loaded together into a single PyTorch tensor, and we'll generate the associated attention mask that tells the model which tokens are padding tokens that can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac068d4-45f2-48c3-950d-465abddd5e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1711766/1225001161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtokenized_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "\n",
    "import data_tools as dtools\n",
    "\n",
    "# Use a tokenize function to deal with tokenization and (batch) padding:\n",
    "#    -- all tokenized strings in a batch need to be padded to the same length \n",
    "#       to be loaded into a PyTorch tensor together\n",
    "def tokenize_function(example):\n",
    "    full_qa = dtools.joke_as_qa(example['setup'], example['punchline'])\n",
    "    q = [x[:x.find('Answer:')].strip() for x in full_qa]\n",
    "    a = [x[x.find('Answer:'):].strip() for x in full_qa]\n",
    "    return tokenizer(q, a, padding=\"max_length\", max_length=60, truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e34e77-105d-47b6-8b85-a6ac5dfaf199",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Notice that the tokenization process has generated and added the token \"input_ids\", \"token_type_ids\", and \"attention_mask\" to our data structure.  These features are what gets input to the model training process.\n",
    "    \n",
    "We also need to add the classification labels that we use to distinguish \"real\" from \"fake\" jokes.  In our case, the \"real\" data all have *score>0*, while \"fake\" data have *score=0*, so we will map everything with *score>0* to have *label=1* and everything with *score=0* to have *label=0*.\n",
    "    \n",
    "Finally, we want to drop the input columns from the dataset, now that we've generated the token lists, attention masks, and labels that we will pass to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88efba32-8799-4a93-ac78-dd0734de7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-822dfa901264c453.arrow\n",
      "Loading cached processed dataset at /home/jupyter-genevievegraves/.cache/huggingface/datasets/csv/default-22e578e895d47822/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-0c896bf6cf0df668.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
      "        num_rows: 2056\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
      "        num_rows: 881\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(lambda batch: {\"labels\": [int(x > 0) for x in batch[\"score\"]]}, batched=True)\n",
    "\n",
    "# Clean up / reformat data to fit into a PyTorch DataLoader\n",
    "# We don't need the text strings themselves anymore\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"setup\", \"punchline\", \"score\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc43dfa-be99-4dfe-8252-453adf92bb14",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Now we're ready to do the fine-tuning training of our classifier!  The training loop itself is implemented in the *train_classifier()* function defined in [model_tools.py](model_tools.py).\n",
    "    \n",
    "We'll train through just 3 epochs with our downsampled training set, just to see how well BERT does with minimal training.  The fake jokes looked pretty different from the real ones, so it shouldn't be too hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1812b626-fe16-4411-a14d-c73a34d3d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 257/771 [00:26<00:53,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.018, Accuracy: 0.967, F1: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 514/771 [00:58<00:27,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.070, Accuracy: 0.952, F1: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [01:30<00:00,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.010, Accuracy: 0.972, F1: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [01:34<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as models/ClassifyJokes_bert_0.01subset_2021-12-17.pt\n"
     ]
    }
   ],
   "source": [
    "model = mtools.train_classifier(tokenized_datasets, model, epochs=3)\n",
    "\n",
    "from datetime import datetime\n",
    "checkpoint_name = checkpoint.split('/')[-1].split('-')[0]\n",
    "filename = 'models/ClassifyJokes_{}_{:4.2f}subset_{}'.format(checkpoint_name,1.0/downsample_factor,datetime.now().date())+'.pt'\n",
    "\n",
    "from torch import save\n",
    "print('Saving model as {}'.format(filename))\n",
    "save(model,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068435df-de1b-49d1-8390-a1f88ed45d60",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "As expected, the classifier does pretty well with minimal training: better than 95%.  It may not even be able to improve much with the full training set.  It takes ~30 seconds/epoch to run on 1% of the full training set, so it should take a couple of hours to run 3 epochs with the full training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b45a0-bf08-4c63-b6a5-9be1f995404e",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The steps here have been encapsulated in the function *classify_punchlines()*, implemented in [punchline_classifier.py](punchline_classifier.py), so you can run the entire process documented above with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36d6b44-c694-46b0-85ab-94d802a3754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from punchline_classifier import classify_punchlines\n",
    "\n",
    "# train_files = ['data/short_jokes_train.csv','data/short_jokes_train_fake.csv']\n",
    "# test_files = ['data/short_jokes_test.csv','data/short_jokes_test_fake.csv']\n",
    "\n",
    "# # Set downsample=1 or leave out to train on the full training set (it defaults to 1)\n",
    "# model = classify_punchlines(train_files, test_files, downsample=20)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc04387-6ab3-4998-a36d-551b5aa9550a",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Using the entire dataset to train the classifier takes a couple of hours and gives only marginal improvement (~98% accuracy).  If you want to run it, we recommend running it from the command line in a detached screen, as in [2.FakePunchlines](2.FakePunchlines.ipynb).\n",
    "\n",
    "* `$> screen -S train_class`\n",
    "* `$> python punchline_classifier.py --train data/short_jokes_train.csv,data/short_jokes_train_fake.csv --test data/short_jokes_test.csv,data/short_jokes_test_fake.csv`\n",
    "\n",
    "Then \"Ctl-a d\" to detach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1040dcc-020d-4fde-add2-00b6918a78ee",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "When the model is finished running, we can load it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9eead96-43ab-4f95-9f9a-58757bba95ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import load\n",
    "model = load(filename)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b069b25-768f-406a-a944-6f374989e18d",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Let's take a look at how well the predictions do, and look at examples that the classifier got wrong to understand what it can do and what its limitations are.\n",
    "    \n",
    "We start by making predictions for our test data and comparing it to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "38d4bde7-144a-4154-9ba9-f6f387539a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "111 batches to process (batch_size=8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:03<00:00, 35.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      0    1\n",
      "labels          \n",
      "0       431    9\n",
      "1        16  425\n",
      "\n",
      "       425 real jokes that the classifier correctly predicted to be real\n",
      "       431 fake jokes that the classifier correctly predicted to be fake\n",
      "        16 real jokes that the classifier thought were fake\n",
      "         9 fake jokes that the classifier thought were real\n"
     ]
    }
   ],
   "source": [
    "pred = mtools.classify_punchlines(tokenized_datasets['test'],model)\n",
    "labels = list(tokenized_datasets['test']['labels'].squeeze().numpy())\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = None   # don't truncate the column text\n",
    "df = pd.DataFrame()\n",
    "df['labels'] = labels\n",
    "df['pred'] = pred\n",
    "df['jokes'] = [dtools.joke_as_qa(x['setup'], x['punchline'])[0] for x in dataset['test']]\n",
    "confusion_matrix = df.groupby(['labels','pred']).size().unstack(fill_value=0)\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "print('{:>10d} real jokes that the classifier correctly predicted to be real'.format(confusion_matrix[1].iloc[1]))\n",
    "print('{:>10d} fake jokes that the classifier correctly predicted to be fake'.format(confusion_matrix[0].iloc[0]))\n",
    "print('{:>10d} real jokes that the classifier thought were fake'.format(confusion_matrix[0].iloc[1]))\n",
    "print('{:>10d} fake jokes that the classifier thought were real'.format(confusion_matrix[1].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "474524d4-c946-4a73-9a11-fa612b12967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the real jokes the classifier thought were fake:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>jokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: DATE: So what do you do? Answer: ME: I race cars. HER: That's so cool. Have you won many races? ME: No, the cars are much faster.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What did Riker call his first born? Answer: Number 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What's the difference between 16 and 26? Answer: There is none.   When you're 16, you're crying if you're pregnant.  When you're 26, you're crying if you're pregnant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What do you call it when you buy a ticket for a chance to win a spotted, long-necked mammal? Answer: A giraffle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Why is it so sad to be an egg? Answer: Because you get smashed once, laid once and the only bird to sit on your face is your mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What do you call a long, skinny fish wearing makeup and a suit of armor? Answer: Pretty Sir Eel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Wanna hear a joke about Sodium? Answer: Na.     What about a joke about Sodium Hypobromite?     Na Bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What’s the worst part about having Alzheimer’s? Answer:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What do you call a phallic, prickly plant in the desert? Answer: A Cocktus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Did you hear about the guy who mixed viagras and laxatives? Answer: He didn't know if he was coming or going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What do you call a short psychic who got away with murder? Answer: A small medium at large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What does Matthew McConnaughey call Nazis when he's trying to bring them into the mainstream? Answer: Alt-right, alt-right, alt-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: How many deadbeat dads does it take to change a lightbulb? Answer: I wouldn't know, mine's never around.  (Alternately: \"Well, he went out to get one...\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What is communism's favorite chemical element? Answer: [Unununium.](http://www.chemicalelements.com/elements/uuu.html)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What language do eagles program in? Answer: [C#](https://np.reddit.com/r/pics/comments/3tp03o/in_canada_we_have_some_nice_falcons/cx8608n)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: What's an Australian Kiss? Answer: A French kiss down under ;)   *first post here, a coworker of mine told me the joke. Go easy :)*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels  pred  \\\n",
       "54        1     0   \n",
       "67        1     0   \n",
       "111       1     0   \n",
       "112       1     0   \n",
       "131       1     0   \n",
       "139       1     0   \n",
       "157       1     0   \n",
       "172       1     0   \n",
       "251       1     0   \n",
       "280       1     0   \n",
       "325       1     0   \n",
       "333       1     0   \n",
       "367       1     0   \n",
       "404       1     0   \n",
       "406       1     0   \n",
       "421       1     0   \n",
       "\n",
       "                                                                                                                                                                                jokes  \n",
       "54                                        Question: DATE: So what do you do? Answer: ME: I race cars. HER: That's so cool. Have you won many races? ME: No, the cars are much faster.  \n",
       "67                                                                                                                     Question: What did Riker call his first born? Answer: Number 1  \n",
       "111  Question: What's the difference between 16 and 26? Answer: There is none.   When you're 16, you're crying if you're pregnant.  When you're 26, you're crying if you're pregnant.  \n",
       "112                                                        Question: What do you call it when you buy a ticket for a chance to win a spotted, long-necked mammal? Answer: A giraffle.  \n",
       "131                                     Question: Why is it so sad to be an egg? Answer: Because you get smashed once, laid once and the only bird to sit on your face is your mother  \n",
       "139                                                                         Question: What do you call a long, skinny fish wearing makeup and a suit of armor? Answer: Pretty Sir Eel  \n",
       "157                                                                  Question: Wanna hear a joke about Sodium? Answer: Na.     What about a joke about Sodium Hypobromite?     Na Bro  \n",
       "172                                                                                                                 Question: What’s the worst part about having Alzheimer’s? Answer:  \n",
       "251                                                                                             Question: What do you call a phallic, prickly plant in the desert? Answer: A Cocktus.  \n",
       "280                                                            Question: Did you hear about the guy who mixed viagras and laxatives? Answer: He didn't know if he was coming or going  \n",
       "325                                                                              Question: What do you call a short psychic who got away with murder? Answer: A small medium at large  \n",
       "333                                   Question: What does Matthew McConnaughey call Nazis when he's trying to bring them into the mainstream? Answer: Alt-right, alt-right, alt-right  \n",
       "367              Question: How many deadbeat dads does it take to change a lightbulb? Answer: I wouldn't know, mine's never around.  (Alternately: \"Well, he went out to get one...\")  \n",
       "404                                                  Question: What is communism's favorite chemical element? Answer: [Unununium.](http://www.chemicalelements.com/elements/uuu.html)  \n",
       "406                              Question: What language do eagles program in? Answer: [C#](https://np.reddit.com/r/pics/comments/3tp03o/in_canada_we_have_some_nice_falcons/cx8608n)  \n",
       "421                                     Question: What's an Australian Kiss? Answer: A French kiss down under ;)   *first post here, a coworker of mine told me the joke. Go easy :)*  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here are the real jokes the classifier thought were fake:')\n",
    "df[(df['pred']==0) & (df['labels']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47c8ce7a-0769-4815-ab99-7cc61a41c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the fake jokes the classifier thought were real:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>jokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What would Soviet Travis Scott name his album? Answer: \"Skryak\" means \"Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What’s the difference between an egg and a wank? Answer: Why is it a wank? I'm not saying you should do an egg wank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What was the last line of code Dennis Ritchie wrote? Answer: I copied 1 12 25 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What did the Gen Z baker yell when he tossed the dough? Answer: I don't think it was. It was not even close to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What do you call the other side of the coconut? Answer: The other side of the coconut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What does a sneezing nut sound like? Answer: Earring piercing sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What do you call a sex scene involving Odysseus and Achilles? Answer: Who the hell does the other player look like?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: What do you call it when a blonde dyes her hair brown? Answer: Rent this movie  Teaser (Teaser) - M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Damn girl are you a smoke detector? Answer: DONE!  Answer: Why would you pick this girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels  pred  \\\n",
       "468       0     1   \n",
       "517       0     1   \n",
       "597       0     1   \n",
       "615       0     1   \n",
       "717       0     1   \n",
       "751       0     1   \n",
       "795       0     1   \n",
       "838       0     1   \n",
       "853       0     1   \n",
       "\n",
       "                                                                                                                              jokes  \n",
       "468                                          Question: What would Soviet Travis Scott name his album? Answer: \"Skryak\" means \"Cream  \n",
       "517  Question: What’s the difference between an egg and a wank? Answer: Why is it a wank? I'm not saying you should do an egg wank.  \n",
       "597                                      Question: What was the last line of code Dennis Ritchie wrote? Answer: I copied 1 12 25 25  \n",
       "615    Question: What did the Gen Z baker yell when he tossed the dough? Answer: I don't think it was. It was not even close to me.  \n",
       "717                                 Question: What do you call the other side of the coconut? Answer: The other side of the coconut  \n",
       "751                                                  Question: What does a sneezing nut sound like? Answer: Earring piercing sounds  \n",
       "795   Question: What do you call a sex scene involving Odysseus and Achilles? Answer: Who the hell does the other player look like?  \n",
       "838                   Question: What do you call it when a blonde dyes her hair brown? Answer: Rent this movie  Teaser (Teaser) - M  \n",
       "853                               Question: Damn girl are you a smoke detector? Answer: DONE!  Answer: Why would you pick this girl  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here are the fake jokes the classifier thought were real:')\n",
    "df[(df['pred']==1) & (df['labels']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fcf70-2b05-4358-9596-ebed57003a66",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "The classifier was able to do a good job sorting out the real jokes from the ones with AI-generated punchlines.  That means pre-trained, straight-out-of-the-box GPT-2 is not able to fool BERT (or, if we're going to anthropomorphize the AIs, GPT-2 can't make BERT laugh!).  \n",
    "    \n",
    "Let's see if GPT-2 can do better once it has been fine-tuned on a set of real jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e727cb6-7bd2-48b2-ad29-77df53ab4176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

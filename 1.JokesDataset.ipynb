{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b919584c-fec0-4405-81ff-de138a38c6ca",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "## 1. The Jokes Dataset\n",
    "\n",
    "To train a joke-telling AI and test its performance, we need a dataset of jokes.  Here, we'll use the \"One Million Reddit Jokes\" dataset, which covers jokes from the /r/jokes subreddit from April 1, 2020 and earlier.  The jokes dataset is provided here in `./data/one-million-reddit-jokes.csv.`  You can also download the jokes dataset directly from Kaggle [here](https://www.kaggle.com/pavellexyr/one-million-reddit-jokes).\n",
    "\n",
    "Let's start by reading in the jokes dataset, seeing what we have, and cleaning it up a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a33455-f743-4014-979c-c343cecdb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the raw jokes dataset\n",
    "filename = '/opt/cloudburst/shared/nlp_puchlines/one-million-reddit-jokes.csv'\n",
    "print('Reading in a lot of jokes...')\n",
    "raw_jokes = pd.read_csv(filename,keep_default_na=False)\n",
    "\n",
    "# Print out the column names with a single example of the data in each column\n",
    "print('{} jokes with the following columns (column name: example) '.format(raw_jokes.shape[0]))\n",
    "for c in raw_jokes.columns:\n",
    "    print('  {:>15}: {}'.format(c,raw_jokes.iloc[1][c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2708d8a4-f06f-4338-aacb-075db441dbf3",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Let's look at a few example rows from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3559b-2aec-4552-9241-447848b50103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first three rows\n",
    "raw_jokes.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72c3e4-eb69-4fbc-8f95-2b8053296de3",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Of these columns, the only ones of relevence to us are the last 3: \n",
    "* `title` is usually used as the joke \"setup\"\n",
    "* `selftext` stores the joke \"punchline\"\n",
    "* `score` is the number of upvotes the joke received and can be used as a metric of \"joke quality\"\n",
    "\n",
    "It would be nice if we could use `subreddit.nsfw` to filter out inappropriate jokes (crude, hyper-sexualized, racist, homophobic, sexist, or otherwise objectionable) but sadly `subreddit.nsfw = False` for everything in this dataset, despite that fact that many of the jokes are clearly NOT safe for work.  We'll discuss the problem of inappropriate jokes further later.\n",
    "\n",
    "Here are the top 5 most common punchlines in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb32722-7e6c-4bf7-8227-af401d6803ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the value and the number counts for the 5 most common punchlines in the dataset\n",
    "raw_jokes['selftext'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6a594-9dd8-41a4-b752-ee58e53c44a1",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Many of the jokes have been removed or deleted (maybe because they were inappropriate and the author or a moderator thought better of it?...).  We don't want these in our dataset.  \n",
    "    \n",
    "Some of them may be using the text \"[removed]\" as their actual punchline, in a self-referential meta joke about Reddit jokes.  We don't really want those either.\n",
    "    \n",
    "But what is going on with the jokes whose punchlines are blank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c295c-8751-4725-b8d1-078b38bca9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None   # don't truncate the column text\n",
    "\n",
    "# Get the jokes with blank punchlines (selftext=='')\n",
    "#    Then show values & counts for the 5 most common setups\n",
    "blank_punchline_counts = raw_jokes[raw_jokes['selftext']=='']['title'].value_counts()\n",
    "blank_punchline_counts.rename_axis('title').reset_index(name='counts').set_index('counts')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b25c8-ef92-47fd-acb2-fd878174994a",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Okay, I get it.  Donald Trump is a joke.  My life is a joke.  Feminism is a joke.  Ha ha.\n",
    "\n",
    "But this raises the larger issue that jokes can take many different narrative forms.  If we're hoping to get an AI to learn to tell jokes, we should start with a somewhat down-scoped problem. For this exercise, let's only use jokes that take the form of a \"setup\" question, followed by a \"punchline\" answer, e.g., \n",
    "\n",
    "* Question: Why did the chicken cross the road?\n",
    "* Answer: To get to the other side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f4380-4bdb-43da-a272-0f8be9e7e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the jokes dataset:\n",
    "#   - get rid of removed or deleted punchlines\n",
    "#   - replace newlines w/ spaces (easier to read)\n",
    "#   - require the setup to be a question\n",
    "#   - remove blank punchlines (length < 1)\n",
    "\n",
    "remove = ['[removed]','[deleted]','\\[removed\\]']   # We'll remove jokes with these punchlines\n",
    "use_columns = ['title','selftext','score']  # We only care about these columns\n",
    "\n",
    "jokes = raw_jokes[raw_jokes['selftext'].apply(lambda x: x not in remove)][use_columns]\n",
    "\n",
    "# Rename columns, replace newlines with spaces\n",
    "jokes = jokes.rename(columns={'title':'setup','selftext':'punchline'})\n",
    "jokes['setup'] = jokes['setup'].apply(lambda x: x.replace('\\n',' ').replace('\\r',' '))\n",
    "jokes['punchline'] = jokes['punchline'].apply(lambda x: x.replace('\\n',' ').replace('\\r',' '))\n",
    "\n",
    "# Is the setup a question?\n",
    "jokes['question'] = jokes['setup'].apply(lambda x: True if x[-1]=='?' else False)\n",
    "# How long is the punchline?\n",
    "jokes['punch_length'] = jokes['punchline'].apply(lambda x: len(x.split()))\n",
    "# Only keep jokes with punchlines containing at least one word (some are all blank space)\n",
    "jokes = jokes[jokes['punch_length'] >= 1]\n",
    "\n",
    "print('{} jokes not missing punchlines, with the following columns:\\n'.format(jokes.shape[0]))\n",
    "for c in jokes.columns:\n",
    "    print('  {:>15}: {}'.format(c,jokes.iloc[1][c]))\n",
    "\n",
    "print('\\n{} jokes have setups that are questions'.format(jokes[jokes['question']==True].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41782bc9-4693-4aa9-8d0b-cac510aea84e",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "We probably also want to restrict ourselves to jokes with short(ish) punchlines---the longer we let an AI ramble on, the less sense it tends to make.\n",
    "\n",
    "Let's look at the length of the punchlines for our jokes that are questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65348d-e651-464d-aef2-61dc8e1b58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('NOTE: logarithmic y-axis!')\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,5))\n",
    "plt.rcParams['font.size'] = '18'\n",
    "ax.plot(list(jokes[jokes['question']==True]['punch_length'].value_counts().index),\n",
    "        list(jokes[jokes['question']==True]['punch_length'].value_counts().values),\n",
    "        'go', label='Question jokes')\n",
    "ax.plot(list(jokes[jokes['question']==False]['punch_length'].value_counts().index),\n",
    "        list(jokes[jokes['question']==False]['punch_length'].value_counts().values),\n",
    "        'ro', label='Non-question jokes')\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "ax.set_xlim((0,60))\n",
    "ax.set_ylim((1,1e5))\n",
    "_ = ax.set_xlabel('# words in punchline',size=14)\n",
    "_ = ax.set_ylabel('# Jokes w/ this length punchline',size=14)\n",
    "_ = ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e78d70-8365-4ed9-b1fa-f484610aed37",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Question jokes tend to have short punchlines---typically just a few words long---whereas setups that are not questions often have a longer \"narrative\" format and a long tail of very long punchlines.  Note that the y-axis is logarithmic, so there are ~100x more very long punchlines in the non-question jokes than the question jokes.\n",
    "    \n",
    "Let's stick with \"question\" jokes that have short(ish) punchlines, no more than 20 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc3b61-d5ad-44fc-947f-b67a3ab4bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = jokes[(jokes['question']==True) & (jokes['punch_length'] <= 20)]\n",
    "print('{} Q/A jokes with short punchlines'.format(jokes.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaac8c-3a50-4ef6-adf4-2e48801ec134",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Let's only keep jokes that *at least one* person thought were funny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121afb87-3a16-42b3-b00c-a0cb6a60bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = jokes[jokes['score'] >= 1]\n",
    "print('{} Q/A jokes with short punchlines that got 1+ upvotes'.format(jokes.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9253c-2f08-4d1b-86fa-5cfdb95ea4b7",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "And finally, some jokes get posted to Reddit again and again.  We want to deduplicate those, but we want to count *all* the upvotes received by the joke.  If we assume a Reddit user only sees and upvotes a joke once (rather than upvoting the same joke again and again), we can do that by summing the upvotes for each duplicate entry of a joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed96433-aa39-4499-8a10-56203f99ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the scores for all jokes with the same setup and punchline\n",
    "jokes['score'] = jokes.groupby(['setup', 'punchline'])['score'].transform('sum')\n",
    "# Then drop the duplicate entries\n",
    "jokes = jokes.drop_duplicates(subset=['setup','punchline'])\n",
    "print('{} jokes in the final dataset'.format(jokes.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea104b3-f260-4496-99cd-e580f0f7cbc0",
   "metadata": {},
   "source": [
    "<div style=background-color:#EEEEFF>\n",
    "\n",
    "Let's split the jokes into a training set and a test set.  We'll use a fixed random seed so that we choose the same split each time.\n",
    "    \n",
    "We'll then write the jokes dataset to disk and take a look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11701eea-5c57-4580-a7e6-c194e1bee3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:>10} jokes in our final dataset'.format(jokes.shape[0]))\n",
    "\n",
    "train_frac = 0.7  # Use 70% of jokes for training, 30% for testing\n",
    "seed = 40         # Use a fixed seed for random state so that we always get the same splits\n",
    "mini_count = 300  # Let's also store a small subset of the test data as a \"mini\" test to use during development.\n",
    "\n",
    "jokes_train = jokes.sample(frac=train_frac, axis=0, random_state=seed)\n",
    "jokes_test = jokes[~jokes.index.isin(jokes_train.index)]\n",
    "\n",
    "print('{:>10} jokes in our training set'.format(jokes_train.shape[0]))\n",
    "print('{:>10} jokes in our test set'.format(jokes_test.shape[0]))\n",
    "\n",
    "output_columns = ['setup','punchline','score']\n",
    "outfile = 'data/short_jokes.csv'\n",
    "\n",
    "print('Joke splits written to:')\n",
    "for dset,name in [(jokes,'_all'), \n",
    "                  (jokes_train, '_train'),\n",
    "                  (jokes_test,'_test'),\n",
    "                  (jokes_test.iloc[:mini_count],'_minitest')]:\n",
    "    dset[output_columns].to_csv(outfile.replace('.csv',name+'.csv'), header=True, index=False)\n",
    "    print('{:>10} in {}'.format(dset.shape[0],outfile.replace('.csv',name+'.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6089b3f-c59f-445b-a162-110bde13cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nHere are some examples:')\n",
    "jokes_test.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec756b6-3a89-4dec-b147-d1d83264299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nAnd here are the top-10 scoring short Q/A-type jokes on Reddit:')\n",
    "jokes_sorted = jokes.sort_values('score',ascending=False)\n",
    "jokes_sorted.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1d982-b104-406a-940a-2675c2fa2cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
